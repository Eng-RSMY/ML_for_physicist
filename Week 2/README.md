# Homework Week 2

1. Carefully study the backpropagation algorithm, on paper and in the program (*)
2. Visualize the training of a multi-layer network for some interesting function! Explore reLU vs sigmoid! (*)
3. Analyze the evolution of the slope w during stochastic gradient descent on a cost function given by C=(1/2) sum_j (w x_j - wtilde x_j)^2￼, where ￼x_j are the N samples drawn from a Gaussian distribution in a single training step. (this is an advanced exercise)
